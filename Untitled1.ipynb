{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981ee60-e732-40f9-b860-87d560dfa804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108bc18e-59e9-45da-8df2-5b3a5f764079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c46bb6-4349-4b22-8b7e-5762817d3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8 model\n",
    "yolo_model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a06e589-8b1a-4c28-9fba-823a22e912ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DeepSort tracker\n",
    "tracker = DeepSort(max_age=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83184b26-39cd-47dc-bfe0-3561f38714cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bf13c0-250e-4162-97b9-b532138b2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open multiple RTSP streams\n",
    "rtsp_links = {\n",
    "    0: \"rtsp://username:password@192.168.29.118:554/Streaming/Channels/101\",\n",
    "   # 1: \"rtsp://username:password@192.168.29.118:554/Streaming/Channels/201\",\n",
    "   # 2: \"rtsp://username:password@192.168.29.118:554/Streaming/Channels/301\",\n",
    "   # 3: \"rtsp://username:password@192.168.29.118:554/Streaming/Channels/401\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "702366e9-9fc1-4cdd-b45b-5ba7f07e86ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = {cam_id: cv2.VideoCapture(link) for cam_id, link in rtsp_links.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9f5c9a-89a6-4af8-99c7-00fa420e5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gesture tracking data\n",
    "gesture_times = {}\n",
    "lock_dict = {}  # For locking ID to track ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a81b42-0517-4ff0-9117-3eb6ef645ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for posture classification\n",
    "def classify_posture(landmarks):\n",
    "    left_shoulder = np.array([landmarks[11].x, landmarks[11].y])\n",
    "    right_shoulder = np.array([landmarks[12].x, landmarks[12].y])\n",
    "    left_hip = np.array([landmarks[23].x, landmarks[23].y])\n",
    "    right_hip = np.array([landmarks[24].x, landmarks[24].y])\n",
    "\n",
    "    shoulder_center = (left_shoulder + right_shoulder) / 2\n",
    "    hip_center = (left_hip + right_hip) / 2\n",
    "\n",
    "    vector = shoulder_center - hip_center\n",
    "    angle = np.arctan2(vector[1], vector[0]) * 180 / np.pi\n",
    "\n",
    "    if -20 <= angle <= 20:\n",
    "        return \"Perfect\"\n",
    "    else:\n",
    "        return \"Lazy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bded9dc-3af4-45ed-9869-dd483cb72baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize gesture times dict\n",
    "def init_person(person_id):\n",
    "    if person_id not in gesture_times:\n",
    "        gesture_times[person_id] = {'Perfect': 0, 'Lazy': 0}\n",
    "\n",
    "# Timer\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        for cam_id, cap in caps.items():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            results = yolo_model.predict(frame, classes=[0])  # Detect only persons\n",
    "            detections = []\n",
    "\n",
    "            for result in results:\n",
    "                for box in result.boxes.xyxy.cpu().numpy():\n",
    "                    x1, y1, x2, y2 = box.astype(int)\n",
    "                    conf = result.boxes.conf[0].cpu().numpy()\n",
    "                    detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
    "\n",
    "            tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "            for track in tracks:\n",
    "                if not track.is_confirmed():\n",
    "                    continue\n",
    "                track_id = track.track_id\n",
    "                x, y, w, h = track.to_ltwh()\n",
    "                person_roi = frame[int(y):int(y+h), int(x):int(x+w)]\n",
    "\n",
    "                rgb_roi = cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB)\n",
    "                results_pose = pose.process(rgb_roi)\n",
    "\n",
    "                if results_pose.pose_landmarks:\n",
    "                    posture = classify_posture(results_pose.pose_landmarks.landmark)\n",
    "\n",
    "                    # Lock identity\n",
    "                    if track_id not in lock_dict:\n",
    "                        lock_dict[track_id] = f'Person_{track_id}'\n",
    "\n",
    "                    person_id = lock_dict[track_id]\n",
    "                    init_person(person_id)\n",
    "\n",
    "                    # Time tracking\n",
    "                    gesture_times[person_id][posture] += 1\n",
    "\n",
    "                    # Draw\n",
    "                    color = (0, 255, 0) if posture == 'Perfect' else (0, 0, 255)\n",
    "                    cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), color, 2)\n",
    "                    cv2.putText(frame, f\"{person_id}-{posture}\", (int(x), int(y - 10)),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            # Display\n",
    "            cv2.imshow(f\"Camera {cam_id}\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    print(\"[INFO] Saving CSV results...\")\n",
    "\n",
    "    with open(\"gesture_tracking_summary.csv\", \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Person_ID\", \"Perfect_Time\", \"Lazy_Time\"])\n",
    "        for person_id, times in gesture_times.items():\n",
    "            writer.writerow([person_id, times['Perfect'], times['Lazy']])\n",
    "\n",
    "    for cap in caps.values():\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"[INFO] CSV file saved as gesture_tracking_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f65c23-5cb7-4b97-8ebb-6faa2ffdce0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6661d-c100-4021-a30f-bc3f96de35db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c35c3-a013-4f02-a785-a32b4f76e80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
